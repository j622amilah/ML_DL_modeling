{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e468837-a23e-446e-b5e3-e69353146edb",
   "metadata": {},
   "source": [
    "# Prediction of a missing word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d875ede-407c-41af-ab77-1a7b66ea4fb2",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0102c4-25a3-4930-9e64-132dd162d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd /home/oem2/Documents/Github_analysis_PROJECTS/Using_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1d690-1725-4e9c-98e1-0392db81ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dotenv list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c050b63-cfb7-4cd1-899d-f0737ade7cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot_env_file_exist:  False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# https://pypi.org/project/python-dotenv/\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "dot_env_file_exist = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Returns true or false if .env exists in current directory\n",
    "print('dot_env_file_exist: ', dot_env_file_exist)  \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d0b97-2a41-4e96-9603-ab26ee304407",
   "metadata": {},
   "source": [
    "# Subfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be49a2e8-0521-48fa-80d8-dea2c7d1f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_break_char_index(text_temp):\n",
    "    temp = [text_temp.find('\\n'), text_temp.find('.')]\n",
    "    out = np.sort(temp)\n",
    "    # print('out: ', out)\n",
    "    \n",
    "    foundvals = [i for i in out if i > -1]\n",
    "    if any(foundvals):\n",
    "        ender = min(foundvals)\n",
    "    else:\n",
    "        ender = len(text_temp)  # no values found\n",
    "    # print('ender: ', ender)\n",
    "    \n",
    "    return ender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a7f552-2f46-4810-a106-354a3a4bf1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform plain character text to a sentence array, where each sentence is in a nested array.\n",
    "def text_2_sen(text0):\n",
    "    flag = 0\n",
    "    ender = -1\n",
    "    ender_b4 = ender+1\n",
    "    text_temp = text0 # a temporary variable to not copy over text0\n",
    "    \n",
    "    sen = []\n",
    "    while ender_b4 < len(text_temp):\n",
    "        ender_b4 = ender+1\n",
    "        # print('ender_b4: ', ender_b4)\n",
    "        \n",
    "        ender = get_next_break_char_index(text_temp[ender_b4::]) + ender_b4\n",
    "        # print('ender: ', ender)\n",
    "        \n",
    "        sen.append(text_temp[ender_b4:ender])\n",
    "        # print('sen: ', sen)\n",
    "    \n",
    "    # Remove empty nested arrays \n",
    "    sen = [i for i in sen if any(i)]\n",
    "    # print('sen: ', sen)\n",
    "\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b49eb4-a9de-47e3-a048-b1323878990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_the_number_of_times_a_char_appears(text, char2find):\n",
    "    c = 0\n",
    "    for char in text:\n",
    "        if char == char2find:\n",
    "            c = c + 1\n",
    "    # print('c: ', c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24ea63b-7129-4cfc-a708-6315ae2ca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_from_start_end_marker(sentence):\n",
    "\n",
    "    start_marker = ['(', '{', '[']\n",
    "    end_marker = [')', '}', ']']\n",
    "\n",
    "    clean_sen = sentence\n",
    "    \n",
    "    for ind in range(len(start_marker)): \n",
    "        # print('start_marker[ind]: ', start_marker[ind])\n",
    "\n",
    "        # Count the number of times the marker appears\n",
    "        loops = count_the_number_of_times_a_char_appears(clean_sen, start_marker[ind])\n",
    "\n",
    "        for x in range(loops):\n",
    "            if start_marker[ind] in clean_sen and end_marker[ind] in clean_sen:\n",
    "                start_ind = clean_sen.find(start_marker[ind])\n",
    "                # print('start_ind: ', start_ind)\n",
    "                \n",
    "                end_ind = clean_sen.find(end_marker[ind])\n",
    "                # print('end_ind: ', end_ind)\n",
    "    \n",
    "                if start_ind == 0:\n",
    "                    clean_sen = clean_sen[end_ind+1::]\n",
    "                else:\n",
    "                    clean_sen = clean_sen[0:start_ind-1] + clean_sen[end_ind+1::]\n",
    "            \n",
    "            # print('clean_sen: ', clean_sen)\n",
    "    \n",
    "    return clean_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81bc86-8b1a-473f-a799-0963857a7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_y(selected_y, Y_seq, y):\n",
    "    # --------------------------------\n",
    "    # Decode y\n",
    "    # --------------------------------\n",
    "    # label_tokenizer.sequences_to_texts(Y_train_seq[1:2])\n",
    "    str_in_an_array = [str(i) for i in Y_seq[selected_y:selected_y+1]]\n",
    "    y_word_tflookup = label_tokenizer.sequences_to_texts(str_in_an_array)[0]\n",
    "    # print('y_word_tflookup: ', y_word_tflookup)\n",
    "    \n",
    "    # OR\n",
    "\n",
    "    y_word_ylookup = y[selected_y]\n",
    "    # print('y_word_ylookup: ', y_word_ylookup)\n",
    "    # --------------------------------\n",
    "\n",
    "    return y_word_ylookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ba4b5-0205-4036-83a8-3dcda164efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodetext2seq_predict_decodeseq2text(txt_input, tokenizer, MAXLEN, PADDING, model, label_tokenizer, Y_seq, y):\n",
    "    # Converts text to the created sequence via the tokenizer object\n",
    "    token_list = tokenizer.texts_to_sequences([txt_input])[0]\n",
    "    print('token_list: ', token_list)\n",
    "    \n",
    "    # Pad the sequence\n",
    "    token_list = pad_sequences([token_list], maxlen=MAXLEN, padding=PADDING)\n",
    "    \n",
    "    # Predict the last word: outputs the probabilities of a word being selected\n",
    "    probabilities = model.predict(token_list, verbose=0)\n",
    "    # print('probabilities: ', probabilities)\n",
    "    # print('len(probabilities): ', len(np.ravel(probabilities)))\n",
    "    \n",
    "    # Select the highest probable word : This picks the best lexical match, but maybe not the best grammatic match\n",
    "    selected_y = np.argmax(probabilities)\n",
    "    # print('selected_y: ', selected_y)\n",
    "    \n",
    "    y_word = decode_y(selected_y, Y_seq, y)\n",
    "    \n",
    "    # Select the best 5  probable word :\n",
    "    sorted_prob = np.sort(np.ravel(probabilities))  # sorted in ascending order\n",
    "    sorted_prob = sorted_prob[::-1]  # sorted in descending order\n",
    "    sorted_prob = sorted_prob[0:10]  # Take first 10 of highes probabilities\n",
    "    print('sorted_prob: ', sorted_prob)\n",
    "    \n",
    "    selected_y_list = np.argsort(np.ravel(probabilities)) # sorting in ascending order\n",
    "    selected_y_list = selected_y_list[::-1]  # sorted in descending order\n",
    "    selected_y_list = selected_y_list[0:10]  # Take first 10 of highes probabilities\n",
    "    print('selected_y_list: ', selected_y_list)\n",
    "\n",
    "    y_word_list = []\n",
    "    for i in selected_y_list:\n",
    "        y_word_list.append(decode_y(i, Y_seq, y))\n",
    "\n",
    "    return y_word, y_word_list, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0a459-5b44-4664-8adf-c15bb04e00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_word_selection(probabilities, Y_seq, y):\n",
    "    # Evaluating the word selection\n",
    "    probabilities = np.ravel(probabilities)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(Y_seq)):\n",
    "        str_in_an_array = [str(i) for i in Y_seq[i:i+1]]\n",
    "        y_word = label_tokenizer.sequences_to_texts(str_in_an_array)\n",
    "        df_temp = pd.DataFrame([y_word[0], y[i], Y_seq[i], probabilities[i]]).T\n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "    \n",
    "    df.columns = ['y_word_tflookup', 'y_word_ylookup', 'Y_seq', 'probabilities']\n",
    "    df = df.sort_values(by='probabilities', ascending=False)\n",
    "    df.reset_index(drop=True, inplace=True)  # inplace means keep index inplace, drop means to include the index as a column\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee39a16-6d38-4ad5-820f-528fe0e4538f",
   "metadata": {},
   "source": [
    "# Load the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2559817c-a5ee-45f1-a527-9f960b921e8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Breakfast is the first meal of the day usually eaten in the morning. The word in English refers to breaking the fasting period of the previous night. Various \"typical\" or \"traditional\" breakfast menus exist, with food choices varying by regions and traditions worldwide.\n",
      "\n",
      "History\n",
      "In Old English, a regular morning meal was called morgenmete, and the word dinner, which originated from Gallo-Romance desjunare (\"to break one's fast\"), referred to a meal after fasting. Around mid-13 century, that meaning of dinner faded away, and around 15th century \"breakfast\" came into use in written English to describe a morning meal.\n",
      "\n",
      "Ancient breakfast\n",
      "Ancient Egypt\n",
      "In Ancient Egypt, peasants ate a daily meal, most likely in the morning, consisting of soup, beer, bread, and onions before they left for work in the fields or work commanded by the pharaohs.The traditional breakfast believed to have been cooked in ancient Egypt was fūl (made from fava beans, possibly the ancestor of today's ful medames), baladi bread, made from emmer wheat, and falafel, and a mixture of fava beans with onions, garlic, parsley and coriander.\n",
      "\n",
      "Ancient Greece\n",
      "In Greek literature, there are numerous mentions of ariston, a meal taken not long after sunrise. The Iliad notes this meal with regard to a labor-weary woodsman eager for a light repast to start his day, preparing it even as he is aching with exhaustion. The opening prose of the 16th book of the Odyssey mentions breakfast as the meal being prepared in the morning before attending to one's chores. Eventually ariston was moved to around noon, and a new morning meal was introduced.\n",
      "In the post-Homeric classical period of Greece, a meal called akratisma was typically consumed immediately after rising in the morning. Akratisma (ἀκρατισμός, akratismos) consisted of barley bread dipped in wine (ἄκρατος, akratos), sometimes complemented by figs or olives. They also made pancakes called tēganitēs (τηγανίτης), tagēnitēs (ταγηνίτης). or tagēnias (ταγηνίας), all words deriving from tagēnon (τάγηνον), meaning \"frying pan\". The earliest attested references on tagēnias are in the works of the 5th century BC poets Cratinus and Magnes. Another kind of pancake was staititēs (σταιτίτης), from staitinos (σταίτινος), \"of flour or dough of spelt\", derived itself from stais (σταῖς), \"flour of spelt\". Athenaeus in his Deipnosophistae mentions staititas topped with honey, sesame and cheese.\n",
      "\n",
      "Ancient Rome\n",
      "Romans called breakfast ientaculum. It was usually composed of everyday staples like bread, cheese, olives, salad, nuts, raisins, and cold meat left over from the night before. They also drank wine-based drinks such as mulsum, a mixture of wine, honey, and aromatic spices. 1st century Latin poet Martial said that ientaculum was eaten at 3:00 or 4:00 in the morning, while 16th century scholar Claudius Saumaise wrote that it was typically eaten at 9:00 or 10:00 a.m. It seems unlikely that any fixed time was truly assigned for this meal.Roman soldiers woke up to a breakfast of pulmentus, porridge similar to the Italian polenta, made from roasted spelt wheat or barley that was then pounded and cooked in a cauldron of water.\n",
      "\n",
      "Middle Ages (500–1500)\n",
      "Europe\n",
      "In the European Middle Ages, breakfast was not usually considered a necessary and important meal, and was practically nonexistent during the earlier medieval period. Monarchs and their entourages would spend a lot of time around a table for meals. Only two formal meals were eaten per day—one at mid-day and one in the evening. The exact times varied by period and region, but this two-meal system remained consistent throughout the Middle Ages.\n",
      "Breakfast in some times and places was solely granted to children, the elderly, the sick, and to working men. Anyone else did not speak of or partake in eating in the morning. Eating breakfast meant that one was poor, was a low-status farmer or laborer who truly needed the energy to sustain his morning's labor, or was too weak to make it to the large, midday dinner.\n",
      "In the 13th century, breakfast when eaten sometimes consisted of a piece of rye bread and a bit of cheese. Morning meals would not include any meat, and would likely include 0.4 imperial gallons (1.8 L) of low alcohol-content beers. Uncertain quantities of bread and ale could have been consumed in between meals.By the 15th century, breakfast in western Europe often included meat. By this time, noble men were seen to indulge in breakfast, making it more of a common practice, and by the early 16th century, recorded expenses for breakfast became customary. Breakfast in eastern Europe remained mostly the same as the modern day: a \"continental breakfast\". The 16th century introduction of caffeinated beverages into the European diet was also an addition to breakfast, believed that coffee and tea aid the body in \"evacuation of superfluities\".\n",
      "\n",
      "Modern breakfast (1500–present)\n",
      "Africa\n",
      "Traditionally, the various cuisines of Africa use a combination of locally available fruits, cereal grains and vegetables, as well as milk and meat products. In some parts of the continent, the traditional diet features milk, curd and whey products. A type of porridge is most commonly eaten. In the book The Bible cyclopædia (et al.) published in 1843, it was documented that during this time in the Arab world, Bedouins often utilized locusts mixed with butter for breakfast, spreading the mixture on unleavened bread.\n",
      "\n",
      "Egypt\n",
      "In the book The Bible cyclopædia (et al.) published in 1843, it was documented that Egyptians were early risers that sometimes had a first meal consisting of coffee along with the smoking of a pipe, and did not eat breakfast until noon. At this time, it was documented that Egyptian breakfast foods included bread, cheese, eggs, butter, curds, clotted cream and stewed beans. In addition, fava beans are an established national breakfast dish.\n",
      "\n",
      "Asia\n",
      "Middle East\n",
      "In the Middle East region of Asia, Iftar refers to the evening meal when Muslims break their sawm (fast) during the Islamic month of Ramadan. Iftar is one of the religious observances of Ramadan, and is often done as a community, with people gathering to break their fast together. Iftar is done right after Maghrib (sunset) time. During the month of Ramadan, Muslims replace traditional breakfast with suhoor, an Islamic term referring to the meal consumed early in the morning by Muslims before sawm during daylight hours. The meal is eaten before fajr (dawn).\n",
      "\n",
      "Israel\n",
      "Japan\n",
      "In Japan, it is common to eat miso soup and rice porridge for breakfast.\n",
      "\n",
      "Lebanon\n",
      "In the book The Bible cyclopædia (et al.) it was documented that c. 1843, poor Lebanese people would consume raw leeks with bread for breakfast.\n",
      "\n",
      "Europe\n",
      "Austria\n",
      "The croissant appears to have originated in Vienna, Austria, in 1683.\n",
      "\n",
      "France\n",
      "French breakfasts are often similar to the continental breakfast. French breakfast pastries include apple turnovers, brioche, croissant and pain au chocolat. Croissants have been described as becoming a standard fare in French breakfast cuisine by 1875.\n",
      "\n",
      "Netherlands\n",
      "Breakfast usually consists of bread with a wide variety of cold cuts, cheeses and sweet toppings; such as hagelslag, vlokken, muisjes, gestampte muisjes, chocolate spread, treacle (a thick, dark brown sugar syrup called stroop), apple butter and peanut butter.\n",
      "The word waffle derives from the Dutch word wafel, which itself derives from the Middle Dutch wafele, and is likely the origin of the food as it is known today.\n",
      "\n",
      "United Kingdom\n",
      "In the early 16th century, some physicians warned against eating breakfast, because they said it was not healthy to eat before a prior meal was digested. By the 1550s, however, there were multiple sources that claimed breakfast was an important meal. For example, in 1551, Thomas Wingfield stated that breakfast was essential. In 1589, Thomas Cogan stated that it was unhealthy to miss breakfast in the morning. He was one of the first to claim that it was healthy for those who were not young, ill or elders to eat breakfast.The full breakfast is a staple of British cuisine, and typically consists of bacon, sausages and eggs, often served with a variety of side dishes and a beverage such as coffee or tea. Prior to 1600, breakfast in Great Britain typically included bread, cold meat or fish, and ale. Tea, chocolate and coffee were introduced to Great Britain in the mid-1600s, and in the 1700s coffee and chocolate were adopted as breakfast drinks by the fashionable. Tea eventually became more popular than chocolate as a breakfast drink.\n",
      "\n",
      "North America\n",
      "The first groups known to have produced maple syrup and maple sugar were indigenous peoples living in the northeastern part of North America. According to aboriginal oral traditions, as well as archaeological evidence, maple tree sap was being processed into syrup long before Europeans arrived in the region.\n",
      "\n",
      "Canada\n",
      "While it has been a source of controversy where the lumberjack breakfast came from, the most cited source is that the lumberjack breakfast was first served in a Vancouver hotel, in 1870. The breakfast consisted of eggs, assorted fried pork strips, and flapjacks. It is said by Anita Stewart that the tradition of hearty cooking developed because of men needing the energy for manual labor.\n",
      "\n",
      "Mexico\n",
      "A typical Aztec breakfast often included corn porridge with honey and chillies, or tortillas with beans and salsa.Chilaquiles are a staple breakfast dish that dates back to the times of the Aztecs; they consist of tortilla chips (locally known as \"totopos\") slathered in salsa and usually come with a side of refried beans. Depending on the region or person, they may be eaten with fried or scrambled eggs, pulled chicken, sprinkled cheese, crema, diced onion, or chopped cilantro (coriander) leaves. Eggs are also a staple in Mexican breakfasts, scrambled and fried eggs are usually eaten with tortillas, salsa, and beans; local varieties include huevos rancheros and \"huevos con tortilla\", which are scrambled eggs fried alongside pieces of corn tortillas.\n",
      "Breakfast cereals are also common in Mexico, mainly due to American influence. Health concerns have arisen regarding the nutritional quality of processed breakfast cereal; it is estimated that Mexican preschoolers consume 7% of their total energy intake from processed breakfast cereals and that 6% of Mexican children exclusively have ready-to-eat cereals with milk for breakfast.\n",
      "\n",
      "United States\n",
      "In 1620, waffles were first introduced to North America by pilgrims who had lived in the Netherlands. Later pioneers consumed largely cornmeal-based breakfasts, and would also consume meals such as oatmeal for dinner and lunch. Common breakfast products included corn pone, johnnycakes, ashcakes, hoe-cakes, and corn dodgers. Ashcakes consisted of cornmeal wrapped in cabbage leaves cooked in the ashes of a campfire, while corn pone is baked, corn dodgers are pan fried, and hoe-cakes are similar to pancakes. After the American Civil War, it became fairly common in America to eat sandwiches that were made of ham and eggs. These sandwiches were not strictly consumed in the morning. In 1897, the first true breakfast sandwich recipe was published in a cookbook.Popcorn cereal was consumed by Americans in the 1800s, which typically consisted of popcorn with milk and a sweetener. Cold breakfast cereal has been consumed by Americans since the late 1890s, and during the 1920s a considerable number of new cereals were marketed. The reason for this movement towards cold breakfast cereals was inspired by the Jacksonian-era Clean Living Movement (1830–1860). This movement focused on a lot of lifestyle changes, but specific to breakfast it claimed that eating bacon, eggs, pancakes and hot coffee was too indulgent. The first prepared cold breakfast cereal marketed to American consumers was created by Dr. John Harvey Kellogg, who introduced it in 1878 and named it granola. The product was prepared with baked wheat, oatmeal and cornmeal, and was the first brand-name breakfast cereal in the United States.Canned fruit juice became prominent as a breakfast beverage after the discovery of vitamins. C. 1900, orange juice as a breakfast beverage was a new concept. The development of frozen orange juice concentrate began in 1915, and in the 1930s it was produced by several companies. Additionally, mass-produced tomato juice began to be marketed in the mid-1920s, and became a popular breakfast drink a few years thereafter.\n",
      "\n",
      "Effect on health\n",
      "While breakfast is commonly referred to as \"the most important meal of the day\", some contest the positive implications of its \"most important\" status.\n",
      "\n",
      "Scientific findings\n",
      "Some epidemiological research indicates that having breakfast high in rapidly available carbohydrates increases the risk of metabolic syndrome.Memory was found to be adversely affected in subjects of a study who had not eaten their breakfast (q.v. also Studies using mice under this heading). Intelligence was not affected. Children aged within 8 and 11 years were found to have differing brainwave; EEG activity states, causative to breakfast consumption.  Non-breakfasting children were observed to have higher activity of upper and lower theta wave, alpha wave, and delta wave, which indicated a causative relationship of breakfast consumption to memory function in the subjects.A review of 47 studies associating breakfast to (i) nutrition, (ii) body weight and (iii) academic performance found amongst those who had eaten breakfast: (i) better nutrition profiles, many studies found less weight (ii) irrespective of greater calorific consumption per day, although a number did not find this correlation, (iii) studies suggested a possible link to better academic performance in the breakfast eating groups (q.v. Benton and Parker 1998, under this heading).The influence of breakfast on managing body weight is unclear.\n",
      "\n",
      "Healthy choice\n",
      "Present professional opinion is largely in favor of eating breakfast, but skipping breakfast might be better than eating unhealthy foods.\n",
      "\n",
      "See also\n",
      "References\n",
      "Cited sources\n",
      "Albala, Ken (2002). Hunting for Breakfast in Medieval and Early Modern Europe. Devon, UK.{{cite book}}:  CS1 maint: location missing publisher (link)\n",
      "Anderson, Heather Arndt (2013). Breakfast: A History. AltaMira Press. ISBN 0759121656.\n",
      "Goodhugh, William; Cooke Taylor, William, eds. (1843). The Bible cyclopædia: or, Illustrations of the civil and natural history of the sacred writings. Oxford University.\n",
      "\n",
      "Further reading\n",
      "\n",
      "Kealey, Terence (2016). Breakfast Is a Dangerous Meal: Why You Should Ditch Your Morning Meal for Health and Wellbeing. London: Fourth Estate. ISBN 978-0008172343. OCLC 994867927.\n",
      "History of breakfast\n",
      "Breakfast: A History. ISBN 9780759121638\n",
      "The English Breakfast: The Biography of a National Meal, with Recipes. ISBN 0857854542\n",
      "Eating History: Thirty Turning Points in the Making of American Cuisine. ISBN 0231140932\n",
      "Food and Cooking in Victorian England: A History. ISBN 0275987086\n",
      "Cuisine and Culture: A History of Food and People. ISBN 1118098757\n",
      "Ency Kitchen History ISBN 0203319176 (scroll down in preview)\n",
      "A History of Food. ISBN 144430514X\n",
      "Southern Food: At Home, on the Road, in History. ISBN 0807844179\n",
      "Internal Cleansing, Revised 2nd Edition. ISBN 0307874419\n",
      "Corn Meal for Breakfast, Dinner, Supper. ISBN 1149900814\n",
      "Albala, Ken (2008). Pancake: A Global History. Reaktion Books.\n",
      "History of breakfast cereal\n",
      "Handbook of Cereal Science and Technology. ISBN 0824782941\n",
      "Chemistry and Technology of Cereals as Food and Feed. ISBN 0442308302\n",
      "An Uncommon History of Common Things. ISBN 1426204205\n",
      "An Irresistible History of Southern Food: Four Centuries of Black Eyed Peas, Collard Greens, and Whole Hog Barbecue. ISBN 1609491939\n",
      "Foods and Nutrition Encyclopedia, Volume 1. ISBN 0849389801\n",
      "Other sources\n",
      "Joie de Vivre: Simple French Style for Everyday Living. ISBN 1439106843.\n",
      "Kealey, Terence (2016). Breakfast is a Dangerous Meal: Why You Should Ditch Your Morning Meal For Health and Wellbeing. London: Fourth Estate. ISBN 978-0008172343. OCLC 994867927.\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/Wikipedia-API/\n",
    "import wikipediaapi\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia('MyProjectName', 'en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")\n",
    "\n",
    "p_wiki = wiki_wiki.page(\"Breakfast\")\n",
    "text = p_wiki.text\n",
    "print('text: ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98199a58-67ff-401b-99e8-bf2ade79e481",
   "metadata": {},
   "source": [
    "# Convert the text to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea1ef62d-c38d-466d-82bb-e13cb1d003fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_text2_sentences(text):\n",
    "    \n",
    "    sen = text_2_sen(text)\n",
    "    # print('sen: ', sen)\n",
    "    \n",
    "    # --------------------------------\n",
    "    # Add additonal made-up sentences\n",
    "    # --------------------------------\n",
    "    sen.append('for breakfast it is typical to drink orange juice and eat eggs')\n",
    "    sen.append('for breakfast the most common drink for breakfast is orange juice')\n",
    "    sen.append('breakfast time is often from sunrise to a few hours before lunchtime')\n",
    "    sen.append('for breakfast the most widely sold and bought drink is orange juice and milk')\n",
    "    # print('sen: ', sen)\n",
    "    \n",
    "    # --------------------------------\n",
    "    # Clean the sentences\n",
    "    # --------------------------------\n",
    "    # Make sentences lowercase\n",
    "    sen1 = [i.lower() for i in sen]\n",
    "    \n",
    "    # Remove parentheses and text in between parentheses, so that phrases are gramatically correct\n",
    "    sen2 = [remove_text_from_start_end_marker(i) for i in sen1]\n",
    "    # print('sen2: ', sen2)\n",
    "    \n",
    "    # Split the sentences on a comma to make more short and clear sentences\n",
    "    sen3 = []\n",
    "    for i in sen2:\n",
    "        temp = i.split(',')\n",
    "        for j in temp:\n",
    "            sen3.append(j)\n",
    "    # print('sen3: ', sen3)\n",
    "    \n",
    "    # Remove undesireable characters \n",
    "    to_replace = [\"!\", \";\", '\\n', '</p>', '<a', 'id=', \"href=\", 'title=', 'class=', '</a>', '(', ')', '}', '{',\n",
    "                  '</sup>', '<p>', '</b>', '<sup', '>', '<', '\\\\', '-']\n",
    "    replace_with = ''\n",
    "    \n",
    "    sen4 = []\n",
    "    for i in sen3:\n",
    "        word_array = i.split()\n",
    "        # print('word_array: ', word_array)\n",
    "    \n",
    "        word_array_new = []\n",
    "        for wind, word in enumerate(word_array):\n",
    "            # print('word: ', word)\n",
    "            \n",
    "            out = word # initialization\n",
    "            \n",
    "            for ind, to_replace_val in enumerate(to_replace):\n",
    "                # print('to_replace_val: ', to_replace_val)\n",
    "                out_b4 = out\n",
    "                out = word.replace(to_replace_val, replace_with)\n",
    "    \n",
    "                # Take the shortest out to ensure previous changes are stored\n",
    "                if len(out_b4) < len(out):\n",
    "                    out = out_b4\n",
    "                # print('out: ', out)\n",
    "            \n",
    "            # Stores the last changed word    \n",
    "            word_array_new.append(out)\n",
    "            \n",
    "        sen4.append(' '.join(word_array_new))   \n",
    "    # print('sen4: ', sen4)\n",
    "    \n",
    "    \n",
    "    # --------------------------------\n",
    "    # Remove sentences with less than 10 words. Narrow the sentences down to realistic sentences.\n",
    "    # --------------------------------\n",
    "    sen5 = [i for i in sen4 if len(i.split()) > 10]\n",
    "    # print('sen5: ', sen5)\n",
    "\n",
    "    return sen5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5be1e6-60f0-42bf-816b-726c039e0e3f",
   "metadata": {},
   "source": [
    "# Create y : remove the last word in each sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "accbe54b-5ba6-42db-bc73-d8090599481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  ['breakfast is the first meal of the day usually eaten in the', 'the word in english refers to breaking the fasting period of the previous', 'and around 15th century \"breakfast\" came into use in written english to describe a morning', 'and onions before they left for work in the fields or work commanded by the', \"the opening prose of the 16th book of the odyssey mentions breakfast as the meal being prepared in the morning before attending to one's\", 'a meal called akratisma was typically consumed immediately after rising in the', 'the earliest attested references on tagēnias are in the works of the 5th century bc poets cratinus and', '1st century latin poet martial said that ientaculum was eaten at 3:00 or 4:00 in the', 'it seems unlikely that any fixed time was truly assigned for this', 'made from roasted spelt wheat or barley that was then pounded and cooked in a cauldron of', 'monarchs and their entourages would spend a lot of time around a table for', 'only two formal meals were eaten per day—one at midday and one in the', 'breakfast in some times and places was solely granted to', 'anyone else did not speak of or partake in eating in the', \"was a lowstatus farmer or laborer who truly needed the energy to sustain his morning's\", 'breakfast when eaten sometimes consisted of a piece of rye bread and a bit of', 'uncertain quantities of bread and ale could have been consumed in between', 'breakfast in eastern europe remained mostly the same as the modern day: a \"continental', 'the 16th century introduction of caffeinated beverages into the european diet was also an addition to', 'believed that coffee and tea aid the body in \"evacuation of', 'the various cuisines of africa use a combination of locally available', 'it was documented that during this time in the arab', 'it was documented that egyptians were early risers that sometimes had a first meal consisting of coffee along with the smoking of a', 'iftar refers to the evening meal when muslims break their sawm during the islamic month of', 'an islamic term referring to the meal consumed early in the morning by muslims before sawm during daylight', 'it is common to eat miso soup and rice porridge for', 'poor lebanese people would consume raw leeks with bread for', 'breakfast usually consists of bread with a wide variety of cold', 'and is likely the origin of the food as it is known', 'because they said it was not healthy to eat before a prior meal was', 'there were multiple sources that claimed breakfast was an important', 'thomas cogan stated that it was unhealthy to miss breakfast in the', 'he was one of the first to claim that it was healthy for those who were not', 'chocolate and coffee were introduced to great britain in the', 'and in the 1700s coffee and chocolate were adopted as breakfast drinks by the', 'tea eventually became more popular than chocolate as a breakfast', 'the first groups known to have produced maple syrup and maple sugar were indigenous peoples living in the northeastern part of north', 'maple tree sap was being processed into syrup long before europeans arrived in the', 'while it has been a source of controversy where the lumberjack breakfast came', 'the most cited source is that the lumberjack breakfast was first served in a vancouver', 'it is said by anita stewart that the tradition of hearty cooking developed because of men needing the energy for manual', 'a typical aztec breakfast often included corn porridge with honey and', 'chilaquiles are a staple breakfast dish that dates back to the times of the aztecs they consist of tortilla chips slathered in salsa and usually come with a side of refried', 'and beans local varieties include huevos rancheros and \"huevos con', 'health concerns have arisen regarding the nutritional quality of processed breakfast cereal it is estimated that mexican preschoolers consume 7% of their total energy intake from processed breakfast cereals and that 6% of mexican children exclusively have readytoeat cereals with milk for', 'waffles were first introduced to north america by pilgrims who had lived in the', 'and would also consume meals such as oatmeal for dinner and', 'ashcakes consisted of cornmeal wrapped in cabbage leaves cooked in the ashes of a', 'it became fairly common in america to eat sandwiches that were made of ham and', 'the first true breakfast sandwich recipe was published in a', 'cold breakfast cereal has been consumed by americans since the late', 'and during the 1920s a considerable number of new cereals were', 'the reason for this movement towards cold breakfast cereals was inspired by the jacksonianera clean living', 'and was the first brandname breakfast cereal in the united', 'canned fruit juice became prominent as a breakfast beverage after the discovery of', 'while breakfast is commonly referred to as \"the most important meal of the', 'some epidemiological research indicates that having breakfast high in rapidly available carbohydrates increases the risk of metabolic', 'children aged within 8 and 11 years were found to have differing brainwave eeg activity', 'nonbreakfasting children were observed to have higher activity of upper and lower theta', 'which indicated a causative relationship of breakfast consumption to memory function in the', 'body weight and academic performance found amongst those who had eaten breakfast: better nutrition', 'illustrations of the civil and natural history of the sacred', 'breakfast is a dangerous meal: why you should ditch your morning meal for health and', 'eating history: thirty turning points in the making of american', 'an irresistible history of southern food: four centuries of black eyed', 'breakfast is a dangerous meal: why you should ditch your morning meal for health and', 'for breakfast it is typical to drink orange juice and eat', 'for breakfast the most common drink for breakfast is orange', 'breakfast time is often from sunrise to a few hours before', 'for breakfast the most widely sold and bought drink is orange juice and']\n",
      "y:  ['morning', 'night', 'meal', 'pharaohs', 'chores', 'morning', 'magnes', 'morning', 'meal', 'water', 'meals', 'evening', 'children', 'morning', 'labor', 'cheese', 'meals', 'breakfast\"', 'breakfast', 'superfluities\"', 'fruits', 'world', 'pipe', 'ramadan', 'hours', 'breakfast', 'breakfast', 'cuts', 'today', 'digested', 'meal', 'morning', 'young', 'mid1600s', 'fashionable', 'drink', 'america', 'region', 'from', 'hotel', 'labor', 'chillies', 'beans', 'tortilla\"', 'breakfast', 'netherlands', 'lunch', 'campfire', 'eggs', 'cookbook', '1890s', 'marketed', 'movement', 'states', 'vitamins', 'day\"', 'syndrome', 'states', 'wave', 'subjects', 'profiles', 'writings', 'wellbeing', 'cuisine', 'peas', 'wellbeing', 'eggs', 'juice', 'lunchtime', 'milk']\n"
     ]
    }
   ],
   "source": [
    "sentences = convert_text2_sentences(text)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sentences:\n",
    "    words = i.split()\n",
    "    temp = words[-1]\n",
    "\n",
    "    # The last word needs to be at least 3 characters long\n",
    "    if len(temp) > 3 and temp.isnumeric() != True:\n",
    "        X.append(' '.join(words[0:-1]))  # it automatically removes spaces before and after the sentence\n",
    "        y.append(temp)\n",
    "        \n",
    "print(\"X: \", X)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe6c41-2815-44f9-ae3e-765f3f4a3640",
   "metadata": {},
   "source": [
    "## Create train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11585002-ce36-4c0e-95eb-1a3fee671ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (70,)\n",
      "y.shape:  (70,)\n",
      "X_train.shape:  (56,)\n",
      "X_test.shape:  (14,)\n",
      "y_train.shape:  (56,)\n",
      "y_test.shape:  (14,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"X.shape: \", X.shape)\n",
    "print(\"y.shape: \", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf1a59-04de-4086-8874-940e539a5139",
   "metadata": {},
   "source": [
    "## Encode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "452af70f-cbaf-4083-bf90-5ff3b3d6d1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in word_index: 441\n",
      "word_index: {'<OOV>': 1, 'the': 2, 'of': 3, 'and': 4, 'in': 5, 'breakfast': 6, 'a': 7, 'to': 8, 'was': 9, 'that': 10, 'for': 11, 'is': 12, 'it': 13, 'meal': 14, 'were': 15, 'first': 16, 'as': 17, 'by': 18, 'before': 19, 'have': 20, 'with': 21, 'eaten': 22, 'morning': 23, 'or': 24, 'century': 25, 'consumed': 26, 'time': 27, 'who': 28, 'bread': 29, 'an': 30, 'coffee': 31, 'during': 32, 'eat': 33, 'most': 34, 'cereals': 35, 'usually': 36, 'into': 37, 'they': 38, 'said': 39, 'this': 40, 'from': 41, 'their': 42, 'would': 43, 'not': 44, 'energy': 45, 'been': 46, 'had': 47, 'common': 48, 'consume': 49, 'cold': 50, 'chocolate': 51, 'became': 52, 'maple': 53, 'processed': 54, 'health': 55, 'cereal': 56, 'children': 57, 'juice': 58, 'history': 59, 'drink': 60, 'orange': 61, 'day': 62, 'english': 63, 'refers': 64, 'around': 65, 'came': 66, 'use': 67, 'work': 68, '16th': 69, 'being': 70, 'after': 71, 'are': 72, 'at': 73, '00': 74, 'truly': 75, 'made': 76, 'cooked': 77, 'meals': 78, 'one': 79, 'some': 80, 'times': 81, 'eating': 82, 'when': 83, 'sometimes': 84, 'consisted': 85, 'also': 86, 'tea': 87, 'body': 88, 'available': 89, 'documented': 90, 'early': 91, 'muslims': 92, 'sawm': 93, 'islamic': 94, 'porridge': 95, 'food': 96, 'known': 97, 'because': 98, 'healthy': 99, 'important': 100, 'those': 101, 'introduced': 102, 'syrup': 103, 'living': 104, 'north': 105, 'while': 106, 'has': 107, 'source': 108, 'lumberjack': 109, 'typical': 110, 'often': 111, 'huevos': 112, 'mexican': 113, 'america': 114, 'found': 115, 'activity': 116, 'dangerous': 117, 'why': 118, 'you': 119, 'should': 120, 'ditch': 121, 'your': 122, 'word': 123, 'breaking': 124, 'fasting': 125, 'period': 126, 'previous': 127, '15th': 128, 'written': 129, 'describe': 130, 'onions': 131, 'left': 132, 'fields': 133, 'commanded': 134, 'opening': 135, 'prose': 136, 'book': 137, 'odyssey': 138, 'mentions': 139, 'prepared': 140, 'attending': 141, \"one's\": 142, 'called': 143, 'akratisma': 144, 'typically': 145, 'immediately': 146, 'rising': 147, 'earliest': 148, 'attested': 149, 'references': 150, 'on': 151, 'tagēnias': 152, 'works': 153, '5th': 154, 'bc': 155, 'poets': 156, 'cratinus': 157, '1st': 158, 'latin': 159, 'poet': 160, 'martial': 161, 'ientaculum': 162, '3': 163, '4': 164, 'seems': 165, 'unlikely': 166, 'any': 167, 'fixed': 168, 'assigned': 169, 'roasted': 170, 'spelt': 171, 'wheat': 172, 'barley': 173, 'then': 174, 'pounded': 175, 'cauldron': 176, 'monarchs': 177, 'entourages': 178, 'spend': 179, 'lot': 180, 'table': 181, 'only': 182, 'two': 183, 'formal': 184, 'per': 185, 'day—one': 186, 'midday': 187, 'places': 188, 'solely': 189, 'granted': 190, 'anyone': 191, 'else': 192, 'did': 193, 'speak': 194, 'partake': 195, 'lowstatus': 196, 'farmer': 197, 'laborer': 198, 'needed': 199, 'sustain': 200, 'his': 201, \"morning's\": 202, 'piece': 203, 'rye': 204, 'bit': 205, 'uncertain': 206, 'quantities': 207, 'ale': 208, 'could': 209, 'between': 210, 'eastern': 211, 'europe': 212, 'remained': 213, 'mostly': 214, 'same': 215, 'modern': 216, 'continental': 217, 'introduction': 218, 'caffeinated': 219, 'beverages': 220, 'european': 221, 'diet': 222, 'addition': 223, 'believed': 224, 'aid': 225, 'evacuation': 226, 'various': 227, 'cuisines': 228, 'africa': 229, 'combination': 230, 'locally': 231, 'arab': 232, 'egyptians': 233, 'risers': 234, 'consisting': 235, 'along': 236, 'smoking': 237, 'iftar': 238, 'evening': 239, 'break': 240, 'month': 241, 'term': 242, 'referring': 243, 'daylight': 244, 'miso': 245, 'soup': 246, 'rice': 247, 'poor': 248, 'lebanese': 249, 'people': 250, 'raw': 251, 'leeks': 252, 'consists': 253, 'wide': 254, 'variety': 255, 'likely': 256, 'origin': 257, 'prior': 258, 'there': 259, 'multiple': 260, 'sources': 261, 'claimed': 262, 'thomas': 263, 'cogan': 264, 'stated': 265, 'unhealthy': 266, 'miss': 267, 'he': 268, 'claim': 269, 'great': 270, 'britain': 271, '1700s': 272, 'adopted': 273, 'drinks': 274, 'eventually': 275, 'more': 276, 'popular': 277, 'than': 278, 'groups': 279, 'produced': 280, 'sugar': 281, 'indigenous': 282, 'peoples': 283, 'northeastern': 284, 'part': 285, 'tree': 286, 'sap': 287, 'long': 288, 'europeans': 289, 'arrived': 290, 'controversy': 291, 'where': 292, 'cited': 293, 'served': 294, 'vancouver': 295, 'anita': 296, 'stewart': 297, 'tradition': 298, 'hearty': 299, 'cooking': 300, 'developed': 301, 'men': 302, 'needing': 303, 'manual': 304, 'aztec': 305, 'included': 306, 'corn': 307, 'honey': 308, 'chilaquiles': 309, 'staple': 310, 'dish': 311, 'dates': 312, 'back': 313, 'aztecs': 314, 'consist': 315, 'tortilla': 316, 'chips': 317, 'slathered': 318, 'salsa': 319, 'come': 320, 'side': 321, 'refried': 322, 'beans': 323, 'local': 324, 'varieties': 325, 'include': 326, 'rancheros': 327, 'con': 328, 'concerns': 329, 'arisen': 330, 'regarding': 331, 'nutritional': 332, 'quality': 333, 'estimated': 334, 'preschoolers': 335, '7': 336, 'total': 337, 'intake': 338, '6': 339, 'exclusively': 340, 'readytoeat': 341, 'milk': 342, 'waffles': 343, 'pilgrims': 344, 'lived': 345, 'such': 346, 'oatmeal': 347, 'dinner': 348, 'ashcakes': 349, 'cornmeal': 350, 'wrapped': 351, 'cabbage': 352, 'leaves': 353, 'ashes': 354, 'fairly': 355, 'sandwiches': 356, 'ham': 357, 'true': 358, 'sandwich': 359, 'recipe': 360, 'published': 361, 'americans': 362, 'since': 363, 'late': 364, '1920s': 365, 'considerable': 366, 'number': 367, 'new': 368, 'reason': 369, 'movement': 370, 'towards': 371, 'inspired': 372, 'jacksonianera': 373, 'clean': 374, 'brandname': 375, 'united': 376, 'canned': 377, 'fruit': 378, 'prominent': 379, 'beverage': 380, 'discovery': 381, 'commonly': 382, 'referred': 383, 'epidemiological': 384, 'research': 385, 'indicates': 386, 'having': 387, 'high': 388, 'rapidly': 389, 'carbohydrates': 390, 'increases': 391, 'risk': 392, 'metabolic': 393, 'aged': 394, 'within': 395, '8': 396, '11': 397, 'years': 398, 'differing': 399, 'brainwave': 400, 'eeg': 401, 'nonbreakfasting': 402, 'observed': 403, 'higher': 404, 'upper': 405, 'lower': 406, 'theta': 407, 'which': 408, 'indicated': 409, 'causative': 410, 'relationship': 411, 'consumption': 412, 'memory': 413, 'function': 414, 'weight': 415, 'academic': 416, 'performance': 417, 'amongst': 418, 'better': 419, 'nutrition': 420, 'illustrations': 421, 'civil': 422, 'natural': 423, 'sacred': 424, 'thirty': 425, 'turning': 426, 'points': 427, 'making': 428, 'american': 429, 'irresistible': 430, 'southern': 431, 'four': 432, 'centuries': 433, 'black': 434, 'eyed': 435, 'sunrise': 436, 'few': 437, 'hours': 438, 'widely': 439, 'sold': 440, 'bought': 441}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 7000  # Desired number of vocabolary words that you want in the \"word dictionary\". Tokenize assigns \n",
    "                    # a number to each new word up to this value.\n",
    "oov_tok = \"<OOV>\"   # Text to replace 'out of vocabulary' words\n",
    "\n",
    "# Initialize the Tokenizer class\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# Generate the word index dictionary\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(X) #  (BEST)\n",
    "\n",
    "# Print the length of the word index. This is the number of vocabulary words in the dictionary.\n",
    "word_index = tokenizer.word_index\n",
    "print(f'number of words in word_index: {len(word_index)}')\n",
    "\n",
    "# Print the word index\n",
    "print(f'word_index: {word_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04c113c3-41a0-419a-8764-ca37257b77ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First padded sequence looks like this: \n",
      "\n",
      "[ 6 12  2 16 14  3  2 62 36 22  5  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "Numpy array of all sequences has shape: (70, 120)\n",
      "\n",
      "This means there are 70 sequences in total and each one has a size of 120\n",
      "First padded sequence looks like this: \n",
      "\n",
      "[ 51   4  31  15 102   8 270 271   5   2   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Numpy array of all sequences has shape: (14, 120)\n",
      "\n",
      "This means there are 14 sequences in total and each one has a size of 120\n"
     ]
    }
   ],
   "source": [
    "# Desired length of sequences\n",
    "MAXLEN = 120  # Pick something small \n",
    "# OU\n",
    "# MAXLEN = len(word_index)  # Total length of sequences\n",
    "\n",
    "PADDING = 'post'  # OR 'pre'\n",
    "\n",
    "# -----------------\n",
    "\n",
    "#  (BEST)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad the sequences using the post padding strategy\n",
    "X_seq = pad_sequences(X_seq, maxlen=MAXLEN, padding=PADDING, truncating=PADDING)\n",
    "\n",
    "print(f\"First padded sequence looks like this: \\n\\n{X_seq[0]}\\n\")\n",
    "print(f\"Numpy array of all sequences has shape: {X_seq.shape}\\n\")\n",
    "print(f\"This means there are {X_seq.shape[0]} sequences in total and each one has a size of {X_seq.shape[1]}\")\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# Pad the sequences using the post padding strategy\n",
    "# X_train_seq = pad_sequences(X_train_seq, maxlen=MAXLEN, padding=PADDING, truncating=PADDING)\n",
    "\n",
    "# print(f\"First padded sequence looks like this: \\n\\n{X_train_seq[0]}\\n\")\n",
    "# print(f\"Numpy array of all sequences has shape: {X_train_seq.shape}\\n\")\n",
    "# print(f\"This means there are {X_train_seq.shape[0]} sequences in total and each one has a size of {X_train_seq.shape[1]}\")\n",
    "\n",
    "# -----------------\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences using the post padding strategy\n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=MAXLEN, padding=PADDING, truncating=PADDING)\n",
    "\n",
    "print(f\"First padded sequence looks like this: \\n\\n{X_test_seq[0]}\\n\")\n",
    "print(f\"Numpy array of all sequences has shape: {X_test_seq.shape}\\n\")\n",
    "print(f\"This means there are {X_test_seq.shape[0]} sequences in total and each one has a size of {X_test_seq.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26ba349b-b8f7-4b6a-b3e9-9c6ffd6ba995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize_labels : ONLY if labels are text \n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Way 0: using y_train\n",
    "# -----------------\n",
    "# Instantiate the Tokenizer (no additional arguments needed)\n",
    "# num_words = len(y_train)\n",
    "# label_tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "\n",
    "# Fit the tokenizer on all the labels\n",
    "# label_tokenizer.fit_on_texts(y_train)  # I used all of y, so it can learn words from both y_train and y_test\n",
    "\n",
    "# -----------------\n",
    "# Way 1: using y\n",
    "# -----------------\n",
    "# Instantiate the Tokenizer (no additional arguments needed)  (BEST)\n",
    "num_words = len(y)\n",
    "label_tokenizer = Tokenizer(num_words=num_words)\n",
    "\n",
    "# Fit the tokenizer on all the labels\n",
    "label_tokenizer.fit_on_texts(y)  # I used all of y, so it can learn words from both y_train and y_test\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# Convert labels to sequences (BEST)\n",
    "Y_seq = label_tokenizer.texts_to_sequences(y)\n",
    "\n",
    "# Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n",
    "Y_seq = np.array([i-1 for i in np.array(Y_seq)])\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# Convert labels to sequences\n",
    "# Y_train_seq = label_tokenizer.texts_to_sequences(y_train)\n",
    "\n",
    "# Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n",
    "# Y_train_seq = np.array([i-1 for i in np.array(Y_train_seq)])\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# Convert labels to sequences\n",
    "Y_test_seq = label_tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "# Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n",
    "Y_test_seq = np.array([i-1 for i in np.array(Y_test_seq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f6c77a6-18f5-4842-9058-190a61b24836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq.shape:  (70, 120)\n",
      "Y_seq.shape:  (70,)\n",
      "max(Y_seq):  54\n"
     ]
    }
   ],
   "source": [
    "# Review size of data\n",
    "# -----------------\n",
    "\n",
    "#  (BEST)\n",
    "X_seq = np.array(X_seq)\n",
    "print('X_seq.shape: ', X_seq.shape)\n",
    "\n",
    "Y_seq = np.reshape(Y_seq, (len(Y_seq),))\n",
    "print('Y_seq.shape: ', Y_seq.shape)\n",
    "print('max(Y_seq): ', max(Y_seq))\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# X_train_seq = np.array(X_train_seq)\n",
    "# print('X_train_seq.shape: ', X_train_seq.shape)\n",
    "\n",
    "# Y_train_seq = np.reshape(Y_train_seq, (len(Y_train_seq),))\n",
    "# print('Y_train_seq.shape: ', Y_train_seq.shape)\n",
    "# print('max(Y_train_seq): ', max(Y_train_seq))\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# X_test_seq = np.array(X_test_seq)\n",
    "# print('X_test_seq.shape: ', X_test_seq.shape)\n",
    "\n",
    "# Y_test_seq = np.reshape(Y_test_seq, (len(Y_test_seq),))\n",
    "# print('Y_test_seq.shape: ', Y_test_seq.shape)\n",
    "# print('max(Y_test_seq): ', max(Y_test_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0f738-d1a0-4067-8dd2-b1c2973181f8",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41d51040-af9c-4529-906a-e879e433f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_model(n_a, input_dim, output_dim, input_length, return_sequences, n_outputs, loss_function_type):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "    \n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(n_a, return_sequences=return_sequences)))\n",
    "    # model.add(LSTM(n_a, input_shape=(timesteps_train, feature), return_sequences=return_sequences, return_state=return_state))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    \n",
    "    # Types of W initializer :\n",
    "    initializer = tf.keras.initializers.HeUniform()\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_outputs, activation='softmax', kernel_initializer=initializer))\n",
    "\n",
    "    # Compile the model for training\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    # opt = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "    # opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "    # Select a loss function\n",
    "    if loss_function_type == 'binary':\n",
    "        # Number of input are \n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])  # optimizer='adam'\n",
    "    elif loss_function_type == 'categorical':  \n",
    "        # When to use categorical_crossentropy?\n",
    "        # says categorical_crossentropy work when y is in one-hot form - but this gave an error\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])  # optimizer='adam'\n",
    "    else:\n",
    "        model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['acc'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9c959-28dc-4d8f-97e9-4f69d3604990",
   "metadata": {},
   "source": [
    "## Specify model compile settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f7fd31e-e1e9-4919-8dca-43741593a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=vocab_size     # this is the Size of the vocabulary. You put this instead of word_index, because\n",
    "# you specify this as the max size for the Tokenizer.\n",
    "\n",
    "# ---------------\n",
    "\n",
    "embedding_dim = 16  # Desired output length of the model layer \n",
    "output_dim=embedding_dim      #  Dimension of the dense embedding, the size that you want the output layer to be\n",
    "                              # or the dimension of the vector space for each word\n",
    "\n",
    "# ---------------\n",
    "\n",
    "# Length of maximum sentence sequences (subject to text)\n",
    "input_length=MAXLEN  # Desired length of sequences\n",
    "\n",
    "# ---------------\n",
    "\n",
    "n_a = 32  # hidden layer size\n",
    "return_sequences = True  # obtain an output for each timestep for each batch\n",
    "\n",
    "# ---------------\n",
    "\n",
    "# n_outputs = len(Y_train_seq)\n",
    "n_outputs = len(Y_seq)\n",
    "\n",
    "# ---------------\n",
    "\n",
    "# 2D tensor with shape: (batch_size, input_length)\n",
    "# 3D tensor with shape: (batch_size, input_length, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1cc1d-0a05-4c7b-9b49-b99b323649cc",
   "metadata": {},
   "source": [
    "## Specify callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c37572af-1cb2-4331-9600-bcbac94eb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# Well stop if there is no improvement after 5 epochs, OR if the accuracy reaches 0.9\n",
    "early_stoping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', baseline=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02cab6-1d20-4a84-b600-55977090d96b",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d330542a-4f6c-49c2-a95d-546842867229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 120, 16)           112000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 120, 64)           12544     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7680)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 70)                537670    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 662214 (2.53 MB)\n",
      "Trainable params: 662214 (2.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/src/backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 608ms/step - loss: 4.2560 - acc: 0.0571 - val_loss: 4.2175 - val_acc: 0.0714\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 4.2017 - acc: 0.0429 - val_loss: 4.1816 - val_acc: 0.0714\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 4.1296 - acc: 0.0286 - val_loss: 4.1464 - val_acc: 0.0714\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 4.0768 - acc: 0.0714 - val_loss: 4.1712 - val_acc: 0.0714\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 4.0155 - acc: 0.1286 - val_loss: 4.1239 - val_acc: 0.0714\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 4.0013 - acc: 0.0857 - val_loss: 4.2398 - val_acc: 0.0000e+00\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 3.9905 - acc: 0.0857 - val_loss: 4.0227 - val_acc: 0.0714\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.9450 - acc: 0.1286 - val_loss: 4.0340 - val_acc: 0.0000e+00\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 3.9381 - acc: 0.0714 - val_loss: 3.9985 - val_acc: 0.0000e+00\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 3.9160 - acc: 0.0714 - val_loss: 3.9652 - val_acc: 0.0000e+00\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 3.9006 - acc: 0.0714 - val_loss: 3.9711 - val_acc: 0.0000e+00\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 3.8849 - acc: 0.0714 - val_loss: 3.9657 - val_acc: 0.0000e+00\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 3.8647 - acc: 0.0714 - val_loss: 4.0284 - val_acc: 0.0000e+00\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 3.8792 - acc: 0.0857 - val_loss: 3.8848 - val_acc: 0.0714\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 3.8169 - acc: 0.1429 - val_loss: 3.8599 - val_acc: 0.0714\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 3.8011 - acc: 0.1429 - val_loss: 3.8486 - val_acc: 0.0714\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 3.7628 - acc: 0.1429 - val_loss: 3.8194 - val_acc: 0.0714\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 3.7395 - acc: 0.1429 - val_loss: 3.7981 - val_acc: 0.0714\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 3.6914 - acc: 0.1429 - val_loss: 3.8055 - val_acc: 0.0714\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 3.6546 - acc: 0.1286 - val_loss: 3.7050 - val_acc: 0.1429\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 3.6167 - acc: 0.1714 - val_loss: 3.6231 - val_acc: 0.0714\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 3.5207 - acc: 0.1571 - val_loss: 3.6720 - val_acc: 0.0714\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 3.4691 - acc: 0.1571 - val_loss: 3.5169 - val_acc: 0.0714\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 3.3760 - acc: 0.1571 - val_loss: 3.4439 - val_acc: 0.0714\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 3.2355 - acc: 0.1857 - val_loss: 3.3182 - val_acc: 0.1429\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 3.1113 - acc: 0.1714 - val_loss: 3.0734 - val_acc: 0.1429\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 3.0007 - acc: 0.2143 - val_loss: 2.8837 - val_acc: 0.1429\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 2.8485 - acc: 0.2429 - val_loss: 2.9955 - val_acc: 0.1429\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 2.8179 - acc: 0.2429 - val_loss: 2.7659 - val_acc: 0.2143\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 2.5773 - acc: 0.3286 - val_loss: 2.7690 - val_acc: 0.1429\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.5676 - acc: 0.2857 - val_loss: 2.6522 - val_acc: 0.3571\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 2.5284 - acc: 0.2714 - val_loss: 2.4519 - val_acc: 0.2143\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 2.3151 - acc: 0.3714 - val_loss: 2.4047 - val_acc: 0.1429\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 2.1597 - acc: 0.4286 - val_loss: 2.2938 - val_acc: 0.2857\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 2.0637 - acc: 0.3714 - val_loss: 2.2273 - val_acc: 0.2857\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.9164 - acc: 0.5429 - val_loss: 2.1339 - val_acc: 0.4286\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 1.8574 - acc: 0.5000 - val_loss: 1.9461 - val_acc: 0.4286\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.9499 - acc: 0.4571 - val_loss: 1.8932 - val_acc: 0.5000\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 1.7714 - acc: 0.5143 - val_loss: 1.6664 - val_acc: 0.7143\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.6375 - acc: 0.6429 - val_loss: 1.6153 - val_acc: 0.6429\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.4745 - acc: 0.6429 - val_loss: 1.2992 - val_acc: 0.9286\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3491 - acc: 0.7714 - val_loss: 1.7717 - val_acc: 0.6429\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.6635 - acc: 0.6286 - val_loss: 1.2608 - val_acc: 0.9286\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.2517 - acc: 0.7143 - val_loss: 1.1560 - val_acc: 0.9286\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.2269 - acc: 0.7143 - val_loss: 1.1623 - val_acc: 0.7857\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.1685 - acc: 0.7571 - val_loss: 1.1662 - val_acc: 0.7857\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1660 - acc: 0.7000 - val_loss: 0.9062 - val_acc: 1.0000\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9519 - acc: 0.9571 - val_loss: 0.8699 - val_acc: 0.9286\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.8809 - acc: 0.8714 - val_loss: 1.1717 - val_acc: 0.7143\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0388 - acc: 0.7571 - val_loss: 1.1396 - val_acc: 0.7143\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1401 - acc: 0.6714 - val_loss: 0.7114 - val_acc: 1.0000\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.7200 - acc: 0.8714 - val_loss: 0.6839 - val_acc: 0.9286\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.6634 - acc: 0.9000 - val_loss: 0.8011 - val_acc: 0.7143\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.7318 - acc: 0.8429 - val_loss: 1.6298 - val_acc: 0.5000\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.2482 - acc: 0.7429 - val_loss: 0.6650 - val_acc: 0.8571\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.6146 - acc: 0.9143 - val_loss: 0.6883 - val_acc: 0.8571\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.5771 - acc: 0.9857 - val_loss: 0.4995 - val_acc: 1.0000\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5508 - acc: 0.9143 - val_loss: 0.5687 - val_acc: 0.9286\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.5056 - acc: 0.9429 - val_loss: 0.4102 - val_acc: 1.0000\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.4166 - acc: 0.9714 - val_loss: 0.4270 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f39bdc692d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_type = \"sparse\"\n",
    "model = text_model(n_a, input_dim, output_dim, input_length, return_sequences, n_outputs, loss_function_type)\n",
    "\n",
    "# Train the model\n",
    "# Need to compile the model everytime one wants to retrain the model, other wise it will train the \n",
    "# model starting with the final weights\n",
    "\n",
    "# -----------------\n",
    "# Way 0: using X_train and y_train\n",
    "# -----------------\n",
    "# model.fit(X_train_seq, Y_train_seq, validation_data=(X_test_seq, Y_test_seq), epochs=60, callbacks=[tensorboard_callback])\n",
    "\n",
    "# -----------------\n",
    "# Way 1: using X and y\n",
    "# -----------------\n",
    "model.fit(X_seq, Y_seq, validation_data=(X_test_seq, Y_test_seq), epochs=60, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e97bd-d320-4ad3-a8b1-2ead76920b31",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7c04450-697e-4521-bf82-47c7bc31b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_list:  [11, 6, 1, 33]\n",
      "sorted_prob:  [0.1702227  0.12745717 0.1014429  0.10117909 0.08956861 0.08351177\n",
      " 0.07953458 0.06113645 0.05223711 0.03478472]\n",
      "selected_y_list:  [52  1 37 23  2 48 53 33 54 35]\n",
      "Predicted sentence:  for breakfast I eat movement\n",
      "Predicted sentence:  for breakfast I eat night\n",
      "Predicted sentence:  for breakfast I eat region\n",
      "Predicted sentence:  for breakfast I eat ramadan\n",
      "Predicted sentence:  for breakfast I eat meal\n",
      "Predicted sentence:  for breakfast I eat eggs\n",
      "Predicted sentence:  for breakfast I eat states\n",
      "Predicted sentence:  for breakfast I eat mid1600s\n",
      "Predicted sentence:  for breakfast I eat vitamins\n",
      "Predicted sentence:  for breakfast I eat drink\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_word_tflookup</th>\n",
       "      <th>y_word_ylookup</th>\n",
       "      <th>Y_seq</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>movement</td>\n",
       "      <td>42</td>\n",
       "      <td>0.170223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>night</td>\n",
       "      <td>8</td>\n",
       "      <td>0.127457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>region</td>\n",
       "      <td>30</td>\n",
       "      <td>0.101443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>ramadan</td>\n",
       "      <td>20</td>\n",
       "      <td>0.101179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>meal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.089569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td></td>\n",
       "      <td>hours</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td></td>\n",
       "      <td>breakfast\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td></td>\n",
       "      <td>beans</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td></td>\n",
       "      <td>breakfast</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td></td>\n",
       "      <td>america</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_word_tflookup y_word_ylookup Y_seq probabilities\n",
       "0                   movement       42    0.170223    \n",
       "1                   night          8     0.127457    \n",
       "2                   region         30    0.101443    \n",
       "3                   ramadan        20    0.101179    \n",
       "4                   meal           2     0.089569    \n",
       ".. ..                ...          ..          ...    \n",
       "65                  hours          21    0.000023    \n",
       "66                  breakfast\"     1     0.000023    \n",
       "67                  beans          34    0.000022    \n",
       "68                  breakfast      1     0.000017    \n",
       "69                  america        29    0.000015    \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_test = 1\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "if which_test == 0:\n",
    "    # Test 0: test with made-up sentences\n",
    "    txt_input = 'for breakfast I drink'\n",
    "    txt_input = 'for breakfast I eat'\n",
    "    # txt_input = 'I eat breakfast at'\n",
    "\n",
    "else:\n",
    "    # Test 1: test with sentences from X_train\n",
    "    # Decode the first sequence using the Tokenizer class\n",
    "    num = 4\n",
    "    out = tokenizer.sequences_to_texts(X_seq[num:num+1])\n",
    "    print('out: ', out)\n",
    "    \n",
    "    a = out[0].split()\n",
    "    txt_input = [i for i in a if i != '<OOV>']\n",
    "    txt_input = ' '.join(txt_input)\n",
    "    print('txt_input: ', txt_input)\n",
    "    \n",
    "    # Real answer\n",
    "    y_real = decode_y(num, Y_seq, y)\n",
    "    print('Real sentence: ', txt_input + ' ' + y_real)\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "y_word, y_word_list, probabilities = decodetext2seq_predict_decodeseq2text(txt_input, tokenizer, MAXLEN, PADDING, model, label_tokenizer, Y_seq, y)\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# Predicted answer\n",
    "for i in y_word_list:\n",
    "    print('Predicted sentence: ', txt_input + ' ' + i)\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "df = evaluate_word_selection(probabilities, Y_seq, y)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5b73b63-20ed-4075-95c6-fba64e852163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_word_tflookup</th>\n",
       "      <th>y_word_ylookup</th>\n",
       "      <th>Y_seq</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td></td>\n",
       "      <td>pharaohs</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_word_tflookup y_word_ylookup Y_seq probabilities\n",
       "61                  pharaohs       9     0.000002    "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_real = 'juice'\n",
    "# y_real = 'milk'\n",
    "df[(df['y_word_ylookup'] == y_real)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af29e3b2-e1d0-49c4-b634-455c0eb22ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_word_tflookup</th>\n",
       "      <th>y_word_ylookup</th>\n",
       "      <th>Y_seq</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>night</td>\n",
       "      <td>8</td>\n",
       "      <td>0.127457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  y_word_tflookup y_word_ylookup Y_seq probabilities\n",
       "1                  night          8     0.127457    "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['y_word_ylookup'] == 'night')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4dc24-6598-4782-ad57-c9e6a5444a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['y_word_ylookup'] == 'eggs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5847d6c-f1a5-4a06-8e07-39b395364313",
   "metadata": {},
   "source": [
    "## These results are not bad, but they are not perfect. The best grammatical word is always in the top 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76b50c-d563-4d0f-8d9d-3fc5c7cae03b",
   "metadata": {},
   "source": [
    "# There are several ways to make the result better :\n",
    "\n",
    "- Option 0: I could train the model with more breakfast data OR text data\n",
    "- Option 1: I could use a pre-trained model (fine tuning)\n",
    "- Option 2: I could use a pre-trained model (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935a4b1-7ecb-4c76-b6ea-8326f2214a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3563880-578f-413c-8d99-faeaceae1e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e7fdea-575f-4466-9056-68c96ae8ce63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667290f-1218-462f-a35d-5b1eb00e63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf4a74-8437-494a-8902-09e8f911850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b9439-ee25-4916-b6c9-7f38d7c91dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
